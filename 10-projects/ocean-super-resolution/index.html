<!doctype html>
<html lang="en">

<head>
    <title>Caleb Kruse - Ocean Super Resolution</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport"
        content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <!-- Bootstrap -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-GLhlTQ8iRABdZLl6O3oVMWSktQOp6b7In1Zl3/Jr59b6EGGoI1aFkw7cmDA6j6gD" crossorigin="anonymous">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <!-- css. Last sheet takes priority -->
    <link rel="stylesheet" href="/css/style-v2.css">
    <link rel="stylesheet" href="/css/header-backgrounds.css">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-w76AqPfDkMBDXo30jS1Sgez6pr3x5MlQ1ZAGC+nuZB+EYdgRZgiwxhTBTkF7CXvN"
        crossorigin="anonymous"></script>
</head>

<body>

    <header class="proto-ocean-super-resolution">
        <div class="container-fluid menu">
            <div class="d-flex justify-content-end">
                <a href="/">
                    <button class="button-white">home</button>
                </a>
            </div>
        </div>
    </header>



    <div class="article">
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-lg-8 col-md-10 col-xs-12">
                    <h3 class="article-heading-blue mt-5">10 projects - #1</h3>
                    <h3 class="article-heading-blue mb-0">ocean super resolution</h3>
                    <h5 class="article-heading-black mt-0">using a neural network to increase the resolution of remotely
                        sensed ocean data</h5>

                    <h5>project goal</h5>
                    <p>
                        For most remote sensing applications, there is a tradeoff between temporal and spatial
                        resolution. Either you have high resolution data that is infrequently sampled, or you can have
                        data that is updated frequently, but at a lower resolution.
                    </p>
                    <p>
                        In this project, I was curious whether I could use an <a
                            href="https://idealo.github.io/image-super-resolution/">image super resolution neural
                            network</a> to improve the resolution of remote sensing data in the ocean.
                    </p>

                    <h5>methods</h5>
                    <p>
                        To test this technique, I needed an ocean dataset where there is detailed structure. I chose
                        chlorophyll a concentrations, and sea surface temperatures as measured by the <a
                            href=https://oceancolor.gsfc.nasa.gov/gallery />Aqua/MODIS satellite</a>.
                    </p>
                    <p>
                        For context, chlorophyll a concentration is a proxy for the amount of phytoplankton in the
                        ocean. For biological oceanography, phytoplankton concentrations are one of the most important
                        features to monitor as it forms the base of the oceanic food chain.
                    </p>
                    <p>
                        The MODIS spectrometer aboard the Aqua satellite was launched in 2002. It images the earth every
                        1-2 days. I used level 3 preprocessed monthly composite images found <a
                            href="https://oceancolor.gsfc.nasa.gov/l3/">here</a> in order to fill in many of the gaps in
                        coverage due to cloud cover, while still maintaining the spatial structure that is present in
                        the chlorphyll and temperature distribution.
                    </p>
                    <p>
                        Because the sensing data is grayscale and the super resolution network expects an RGB image, I
                        mapped the intensity to common <a href="https://matplotlib.org/users/colormaps.html"> matplotlib
                            colormaps</a>.
                    </p>
                    <p>
                        Level 3 products (products with the most preprocessing) were most accessible at 4km and 9km per
                        pixel resolutions. For this test, I used the 9km data (low res) as the images to upsample, and
                        4km data (high res) as the ground truth image. I also compared the super resolution images
                        against basic bicubic upsampling.
                    </p>
                    <p>
                        To see and run the code, you can launch a Google colab notebook here: <a
                            href="https://colab.research.google.com/drive/1MexYtGhnvsvI7uEV8Gx9Pg6s0KejKE4Z">Ocean Super
                            Resolution</a>
                    </p>
                    <h5>results</h5>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row justify-content-center">
                <div class="col-lg-8 col-md-10 col-sm-12">
                    <div class="ratio ratio-4x3">
                        <iframe class="juxtapose"
                            src="https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html?uid=d740abb2-8e91-11ea-a879-0edaf8f81e27"></iframe>
                    </div>
                    <p class="caption">ocean temperature - bicubic upsampling vs. super resolution</p>
                </div>

                <div class="col-lg-8 col-md-10 col-sm-12">
                    <div class="ratio ratio-4x3">
                        <iframe class="juxtapose"
                            src="https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html?uid=a9bef1bc-8e91-11ea-a879-0edaf8f81e27"></iframe>
                    </div>
                    <p class="caption">chlorophyll a - high res baseline vs. super resolution</p>
                </div>

                <div class="col-lg-8 col-md-10 col-sm-12">
                    <div class="ratio" style="--bs-aspect-ratio: 83%;">
                        <iframe class="juxtapose"
                            src="https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html?uid=7c0cb094-8e8f-11ea-a879-0edaf8f81e27"></iframe>
                    </div>
                    <p class="caption">ocean temperature - bicubic upsampling vs. super resolution</p>
                </div>

                <div class="col-lg-8 col-md-10 col-sm-12">
                    <div class="ratio" style="--bs-aspect-ratio: 83%;">
                        <iframe class="juxtapose"
                            src="https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html?uid=1f1a3a08-8e91-11ea-a879-0edaf8f81e27"></iframe>
                    </div>
                    <p class="caption">ocean temperature - high res baseline vs. super resolution</p>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-lg-8 col-md-10 col-xs-12">
                    <h5>conclusion</h5>
                    <p>
                        The network certainly accomplishes the goal of upsampling an image and sharpening the output.
                        However, there are a fair number of artifacts present in the outputs.
                    </p>
                    <p>
                        It's questionable though whether the benefits of increased resolution would be strong enough to
                        outweigh the downsides of introducing processing artifacts into the sample.
                    </p>

                    <h5>what would i do next</h5>
                    <ul>
                        <li>
                            I'd be curious whether the network could perform substantially better if trained
                            specifically on remote sensing data. The network pereceptually performed better when using
                            natural color Landsat imagery.
                        </li>
                        <li>
                            Do different color maps impact the outcome? The network certainly uses color patterns from
                            natural images in order to aid the upsampling process. Perhaps the "jet" and "viridis" color
                            schemes are unfamiliar to the network.
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <footer id="footer" class="footer">
            <div class="row align-items-center">
                <div class="col-xs-12 col-6">
                    <div class="footer-socials text-left">
                        <a href="https://twitter.com/clkruse" target="_blank">
                            <i class="fa fa-twitter"></i>
                        </a>
                        <a href="https://www.instagram.com/clkruse" target="_blank">
                            <i class="fa fa-instagram"></i>
                        </a>
                    </div>
                </div>
                <div class="col-xs-12 col-6">
                    <p class="copyright">Â© Caleb Kruse</p>
                </div>
            </div>
        </footer>

        <script>
            mapboxgl.accessToken = 'pk.eyJ1IjoiY2xrcnVzZSIsImEiOiJjaXIxY2M2dGcwMnNiZnZtZzN0Znk3MXRuIn0.MyKHSjxjG-ZcI2BkRUSGJA';
            var map = new mapboxgl.Map({
                container: 'map', // container id
                style: "mapbox://styles/clkruse/ck8s8ml4i0qim1imnbhbkstie", //YOUR TURN: choose a style: https://docs.mapbox.com/api/maps/#styles
                center: [-104.683900, 39.035300], // starting position [lng, lat]
                zoom: 11.5, // starting zoom
            });
        </script>
</body>

</html>